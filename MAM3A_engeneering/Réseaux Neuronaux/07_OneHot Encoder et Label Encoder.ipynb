{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f9366e-daa9-4d4b-bb05-0efa035e169b",
   "metadata": {},
   "source": [
    "# Encodage \n",
    "\n",
    "## One-Hot encodage\n",
    "\n",
    "L'encodage \"one-hot\" (ou \"one-of-K\" encoding ou encodage binaire) est une technique couramment utilisée en machine learning, en particulier en classification, pour représenter des données catégoriques ou des étiquettes de classe de manière numérique. L'objectif de cette technique est de convertir des catégories en vecteurs binaires (0 ou 1) pour les utiliser plus efficacement dans les algorithmes d'apprentissage automatique. Voici comment cela fonctionne :\n",
    "\n",
    "Supposons que vous ayez une variable catégorique, comme \"couleur des fruits\", avec trois catégories possibles : \"rouge\", \"vert\" et \"bleu\". L'encodage one-hot crée trois nouvelles variables binaires, une pour chaque catégorie :\n",
    "\n",
    "* La catégorie \"rouge\" est représentée par (1, 0, 0).\n",
    "* La catégorie \"vert\" est représentée par (0, 1, 0).\n",
    "* La catégorie \"bleu\" est représentée par (0, 0, 1).\n",
    "\n",
    "Chaque variable binaire indique si une observation particulière appartient ou non à une catégorie donnée. Ainsi, une observation qui correspond à \"vert\" aura une valeur de 1 dans la deuxième position (vert) et des zéros dans les autres positions (rouge et bleu).\n",
    "\n",
    "Voici pourquoi l'encodage one-hot est utile :\n",
    "\n",
    "- Compatibilité avec les algorithmes : De nombreux algorithmes d'apprentissage automatique, tels que les réseaux de neurones, les arbres de décision, etc., travaillent mieux avec des données numériques. L'encodage one-hot permet de représenter des catégories de manière numérique tout en évitant d'attribuer un ordre ou une relation ordonnée entre les catégories.\n",
    "\n",
    "- Évite la distorsion : Si vous encodez une variable catégorique avec des entiers (par exemple, 1 pour \"rouge\", 2 pour \"vert\" et 3 pour \"bleu\"), les algorithmes peuvent interpréter involontairement une relation ordonnée entre les catégories (par exemple, \"vert\" est plus grand que \"rouge\"). L'encodage one-hot évite cette distorsion.\n",
    "\n",
    "- Facilité d'interprétation : Les variables binaires one-hot sont faciles à interpréter. Chaque variable indique simplement la présence ou l'absence d'une catégorie particulière.\n",
    "\n",
    "- Prise en charge des catégories multiples : L'encodage one-hot peut également gérer des situations où une observation peut appartenir à plusieurs catégories simultanément. Par exemple, si vous encodez les genres de films, un film peut être à la fois \"action\" et \"science-fiction\", ce qui est difficile à représenter avec une simple variable catégorique.\n",
    "\n",
    "Il est important de noter que l'encodage one-hot peut augmenter considérablement la dimension de vos données si vous avez de nombreuses catégories. Cependant, il est souvent préférable pour la plupart des modèles d'apprentissage automatique. De plus, de nombreuses bibliothèques, y compris TensorFlow et scikit-learn en Python, proposent des outils pour effectuer facilement l'encodage one-hot sur vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec1de60-b392-4431-83ad-4f9f7ceecaa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 14:55:27.219375: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-11 14:55:27.219503: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-11 14:55:31.497544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-10-11 14:55:31.497640: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-11 14:55:31.497722: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (newtown): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.layers' has no attribute 'OneHotEncoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Ajoutez une couche d'encodage one-hot\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneHotEncoding\u001b[49m(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# Remplacez 3 par le nombre de classes dans vos données\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Transformez vos données en utilisant le modèle\u001b[39;00m\n\u001b[1;32m     13\u001b[0m one_hot_encoded_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_data)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.layers' has no attribute 'OneHotEncoding'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Exemple de données d'entraînement (des entiers représentant des classes)\n",
    "train_data = [0, 1, 2, 1, 0]\n",
    "\n",
    "# Créez un modèle séquentiel\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Ajoutez une couche d'encodage one-hot\n",
    "model.add(keras.layers.OneHotEncoding(num_classes=3))  # Remplacez 3 par le nombre de classes dans vos données\n",
    "\n",
    "# Transformez vos données en utilisant le modèle\n",
    "one_hot_encoded_data = model.predict(train_data)\n",
    "\n",
    "# Affichez les résultats\n",
    "print(one_hot_encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f058e-0b47-487b-87af-6b3dcce7db5b",
   "metadata": {},
   "source": [
    "# Label Encoder\n",
    "\n",
    "Keras ne propose pas directement une couche spécifique pour l'encodage des étiquettes (label encoding) comme il le fait pour l'encodage one-hot. Cependant, vous pouvez utiliser la classe **LabelEncoder** de la bibliothèque scikit-learn pour effectuer le label encoding avant d'utiliser vos données avec Keras. Voici comment faire :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895025a0-ca18-49ca-9670-593ed1e7f80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Exemple de données d'étiquettes\n",
    "labels = ['chat', 'chien', 'oiseau', 'chien', 'chat']\n",
    "\n",
    "# Créez une instance de LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ajustez le label encoder aux données et transformez les étiquettes\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Les étiquettes sont maintenant encodées sous forme d'entiers\n",
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ccd8bd-2baf-4e72-93a6-5b803dcfe998",
   "metadata": {},
   "source": [
    "Bien sûr les labels peuvent avoir un encodage \"one-hot label\" (ou \"one-hot encoding with label encoding\") :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b7b3cd-57b1-458f-afec-f546d314f42d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Exemple de données d'étiquettes\n",
    "labels = ['chat', 'chien', 'oiseau', 'chien', 'chat']\n",
    "\n",
    "# Créez une instance de LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ajustez le label encoder aux données et transformez les étiquettes\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Trouvez les catégories uniques dans les étiquettes\n",
    "unique_labels = np.unique(encoded_labels)\n",
    "\n",
    "# Créez un one-hot encoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Préparez les données pour l'encodage one-hot\n",
    "encoded_labels = encoded_labels.reshape(len(encoded_labels), 1)\n",
    "\n",
    "# Effectuez l'encodage one-hot uniquement pour les catégories rares\n",
    "onehot_labels = onehot_encoder.fit_transform(encoded_labels)\n",
    "\n",
    "# Affichez les résultats\n",
    "print(onehot_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
